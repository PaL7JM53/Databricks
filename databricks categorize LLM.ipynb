{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef173a36-db6c-4b7a-bdea-a2c0a569f998",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "this code uses a LLM to categorize sentaces into job categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "05941d7f-433f-412c-b890-28ae7506d3f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df = spark.sql(\"SELECT prompt, occupation FROM dbacademy.labuser12556453_1763383765.llm_train\")\n",
    "display(df)\n",
    "\n",
    "# Convert to Pandas for model training\n",
    "pdf = df.toPandas()\n",
    "\n",
    "# Prepare training data\n",
    "X = pdf[\"prompt\"].tolist()\n",
    "y = pdf[\"occupation\"].tolist()\n",
    "\n",
    "# %pip install transformers datasets mlflow\n",
    "\n",
    "import mlflow\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset\n",
    "\n",
    "# Tokenizer and model selection\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Encode labels\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "num_labels = len(le.classes_)\n",
    "\n",
    "# Tokenize prompts\n",
    "def preprocess(examples):\n",
    "    return tokenizer(examples[\"prompt\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "dataset = Dataset.from_dict({\"prompt\": X, \"label\": y_encoded})\n",
    "dataset = dataset.map(preprocess, batched=True)\n",
    "\n",
    "# Train/test split\n",
    "train_test = dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test[\"train\"]\n",
    "eval_dataset = train_test[\"test\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dcbd6c8e-25b4-46f6-848c-e7bb2cea1499",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=num_labels\n",
    ")\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/dbfs/tmp/results\",\n",
    "    num_train_epochs=2,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    logging_steps=10,\n",
    "    save_steps=10,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset\n",
    ")\n",
    "\n",
    "# Train model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f5742a99-74cb-47c0-94e3-591dc495cc08",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "with mlflow.start_run():\n",
    "    mlflow.transformers.log_model(\n",
    "        transformers_model={\n",
    "            \"model\": model,\n",
    "            \"tokenizer\": tokenizer\n",
    "        },\n",
    "        artifact_path=\"llm_occupation_model\",\n",
    "        task=\"text-classification\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4f78b3b7-4468-440d-b998-a846d40305cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Predict occupation from new prompts\n",
    "def predict_occupation(prompts):\n",
    "    inputs = tokenizer(prompts, truncation=True, padding=\"max_length\", max_length=128, return_tensors=\"pt\")\n",
    "    outputs = model(**inputs)\n",
    "    preds = outputs.logits.argmax(dim=1).numpy()\n",
    "    return le.inverse_transform(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8488daca-4ae1-438a-8e8e-05d4ba9890b5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example usage\n",
    "new_prompts = [\"Write a report on financial analysis.\", \"Design a new software application.\"]\n",
    "predicted_occupations = predict_occupation(new_prompts)\n",
    "display(predicted_occupations)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "LLM2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}